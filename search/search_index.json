{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Introduction \u00b6 What is batect? \u00b6 batect is a tool that makes setting up, sharing and maintaining Docker-based development and testing environments much, much easier. The main benefits of batect are: Consistent, fast, repeatable, isolated builds and test runs everywhere: your computer, your colleagues' computers and on CI Document and share common tasks within your team in a structured way - it's a go script based on Docker Manage dependencies for integration and end-to-end testing (like databases) with ease No installation required, only dependencies are Bash, Docker (v17.06+) and curl * - onboard new team members in minutes Works with any language or framework, your existing CI system, and your chosen language's existing tooling Take advantage of existing Docker images to get started quickly * at the moment, a JVM is also required, but this requirement will be removed before v1.0 What is batect not? \u00b6 a build tool - instead, use your chosen language's existing tooling (eg. Gradle, Rake, CMake or Cargo) from within a batect task a deployment tool - instead, use your target environment's existing tooling (eg. kubectl) from within a batect task a CI tool - instead, use your existing CI tool and have it run batect Why would you use batect? \u00b6 Every application has a build environment - the tools and configuration needed to take the source code and produce an artifact ready for use. However, setting this up can be time consuming and frustrating. Too often new team members' first experience on a project is a few days working out which tools they need to install, and another few days of then discovering the magic combination of tool versions that will happily coexist. And as the application evolves and changes over time, maintaining and updating this environment across all developers' machines and CI agents can be incredibly painful. Similarly, most applications have external dependencies - for example, other services, databases, caches, credential storage systems... the list is endless. Because of this, we would like to run integration, component or journey tests where the application itself (or some part of it) interacts with these external dependencies. In some cases, we'd like to use a real instance of it (eg. a running Postgres instance), and in other cases, we'd like to use a fake (eg. a fake implementation of a downstream service). Either way, installing, configuring and managing all these dependencies takes a lot of work, and making sure they're in a known state before a test run is key to reducing test flakiness. Add in networking gremlins, different operating systems, personal preferences, built-up cruft and manual configuration and you end up with an enormous number of variables that lead to a huge amount of wasted time spent debugging issues that are entirely preventable. batect helps solve these problems by: allowing you to entirely automate the setup of your build and testing environments storing this automation alongside your application code, so that it is versioned and updated just like any other part of your application ensuring that every single command invocation starts with a completely fresh environment based on your configuration file, making it impossible to get out-of-sync from the desired state making use of Docker to do all of this in an isolated and low-overhead way using some smart dependency management logic, parallelism and Docker's caching features to do all of this very, very quickly taking advantage of Docker's networking features to set up an isolated network for every command enabling you to use existing Docker images as-is (or easily use custom Dockerfiles) to quickly get up and running","title":"Introduction"},{"location":"index.html#introduction","text":"","title":"Introduction"},{"location":"index.html#what-is-batect","text":"batect is a tool that makes setting up, sharing and maintaining Docker-based development and testing environments much, much easier. The main benefits of batect are: Consistent, fast, repeatable, isolated builds and test runs everywhere: your computer, your colleagues' computers and on CI Document and share common tasks within your team in a structured way - it's a go script based on Docker Manage dependencies for integration and end-to-end testing (like databases) with ease No installation required, only dependencies are Bash, Docker (v17.06+) and curl * - onboard new team members in minutes Works with any language or framework, your existing CI system, and your chosen language's existing tooling Take advantage of existing Docker images to get started quickly * at the moment, a JVM is also required, but this requirement will be removed before v1.0","title":"What is batect?"},{"location":"index.html#what-is-batect-not","text":"a build tool - instead, use your chosen language's existing tooling (eg. Gradle, Rake, CMake or Cargo) from within a batect task a deployment tool - instead, use your target environment's existing tooling (eg. kubectl) from within a batect task a CI tool - instead, use your existing CI tool and have it run batect","title":"What is batect not?"},{"location":"index.html#why-would-you-use-batect","text":"Every application has a build environment - the tools and configuration needed to take the source code and produce an artifact ready for use. However, setting this up can be time consuming and frustrating. Too often new team members' first experience on a project is a few days working out which tools they need to install, and another few days of then discovering the magic combination of tool versions that will happily coexist. And as the application evolves and changes over time, maintaining and updating this environment across all developers' machines and CI agents can be incredibly painful. Similarly, most applications have external dependencies - for example, other services, databases, caches, credential storage systems... the list is endless. Because of this, we would like to run integration, component or journey tests where the application itself (or some part of it) interacts with these external dependencies. In some cases, we'd like to use a real instance of it (eg. a running Postgres instance), and in other cases, we'd like to use a fake (eg. a fake implementation of a downstream service). Either way, installing, configuring and managing all these dependencies takes a lot of work, and making sure they're in a known state before a test run is key to reducing test flakiness. Add in networking gremlins, different operating systems, personal preferences, built-up cruft and manual configuration and you end up with an enormous number of variables that lead to a huge amount of wasted time spent debugging issues that are entirely preventable. batect helps solve these problems by: allowing you to entirely automate the setup of your build and testing environments storing this automation alongside your application code, so that it is versioned and updated just like any other part of your application ensuring that every single command invocation starts with a completely fresh environment based on your configuration file, making it impossible to get out-of-sync from the desired state making use of Docker to do all of this in an isolated and low-overhead way using some smart dependency management logic, parallelism and Docker's caching features to do all of this very, very quickly taking advantage of Docker's networking features to set up an isolated network for every command enabling you to use existing Docker images as-is (or easily use custom Dockerfiles) to quickly get up and running","title":"Why would you use batect?"},{"location":"Comparison.html","text":"Comparison with other tools \u00b6 Feedback wanted Are you wondering about how batect compares to other tools? Do you have your own reasons for or against batect compared to one of the tools mentioned below? Please file an issue with your questions, comments and feedback. How does batect compare to... ...Vagrant? \u00b6 Vagrant's use of virtual machines means that it is very heavyweight, making it difficult to run multiple projects' environments at once. This is especially problematic on CI servers where we'd like to run multiple builds in parallel. Furthermore, the long-lived nature of virtual machines means that it's very easy for a developer's machine to get out of sync with the desired configuration, and nothing automatically re-provisions the machine when the configuration is changed - a developer has to remember to re-run the provisioning step if the configuration changes. ...using shell scripts to drive Docker? \u00b6 While it's certainly possible, it quickly gets unwieldy and is difficult to effectively parallelise tasks that can run in parallel. It is also difficult to ensure that all resources created during the task, such as containers and networks, are always correctly cleaned up once the task completes, especially if the task fails. ...Docker Compose? \u00b6 In the past, I've used Docker Compose to implement the same idea that is at the core of batect. However, using Docker Compose for this purpose has a number of drawbacks. In particular, Docker Compose is geared towards configuring an application and its dependencies and deploying this whole stack to something like Docker Swarm. Its CLI is designed with this purpose in mind, making it frustrating to use day-to-day as a development tool and necessitating the use of a higher-level script to automate its usage. It also does not elegantly support pulling together a set of containers in different configurations (eg. integration vs journey testing), does each operation serially (instead of parallelising operations where possible) and has one long-standing bug that makes waiting for containers to report as healthy difficult. ...CI tools with a local runner? \u00b6 As an example, both GitLab CI and CircleCI have CLIs that allow you to run your build on your local machine, using the same containers (and therefore environment) as they do when running your build on the CI server. These tools have been designed to primarily be great CI servers, with the local CLI intended to be a convenience to allow developers to test changes to the build configuration, rather than being a day-to-day development tool. batect, on the other hand, was designed from the beginning to be a great day-to-day development tool that also works equally well on CI. Specific drawbacks of these tools compared to using batect include: batect provides a significantly better developer experience, with a simpler, easier to use CLI, clearer and more concise output (with more details available when required), and clearer error messages. One specific example would be the experience when a dependency container fails to become healthy - batect will not only tell you which container did not become healthy, but also automatically display the output from the last health check, and also provides the option to not clean up the dependency containers if they fail to allow you to investigate further. batect supports using local Dockerfiles to define the images used, rather than requiring that all images be pushed to a Docker registry. This provides a number of benefits: Additional configuration or installation of software over and above what is included in the base image can be codified in the Dockerfile, built once per machine that uses it and then cached, saving time over doing this additional configuration or installation at the beginning of each and every build. This also reduces the need to bloat the base image with configuration or software required by only one or two users of the base image, reducing their size and improving maintainability. Enabling changes to be made to the build and testing environments in the same repository as the application's code enhances traceability and understanding of why changes were made - the code change can form part of the same commit as the environmental change required to support it. These tools have only basic support for dependencies in other containers (for example, a database used for integration testing), and require the configuration of other tools such as Dockerize to ensure that dependencies are ready for use before they are used. This does not take advantage of images' built-in health checks and the benefits this mechanism has, such as a warm-up period. Furthermore, this leaves the developer to manually manage transitive dependencies between these containers, and all of the limitations with regard to the images used for the build environment discussed above apply equally to dependency images. These tools don't provide time-saving functionality such as automatically configuring proxies at image build time and in the container . As these tools are designed to run the build and only the build in exactly the same way every time, they do not support passing additional arguments to the task, making it difficult to change options for tasks that may be helpful during development, such as enabling a debugger or more verbose logging. These tools don't support easily mounting the local working copy into the build container, which means they can't be used for tasks that rely on detecting changes to code, such as a continuous unit test task. These tools don't have a way to easily codify and share tasks not used in the build but used by developers, such as a task that spins up the app with stubbed dependencies.","title":"Comparison with other tools"},{"location":"Comparison.html#comparison-with-other-tools","text":"Feedback wanted Are you wondering about how batect compares to other tools? Do you have your own reasons for or against batect compared to one of the tools mentioned below? Please file an issue with your questions, comments and feedback. How does batect compare to...","title":"Comparison with other tools"},{"location":"Comparison.html#vagrant","text":"Vagrant's use of virtual machines means that it is very heavyweight, making it difficult to run multiple projects' environments at once. This is especially problematic on CI servers where we'd like to run multiple builds in parallel. Furthermore, the long-lived nature of virtual machines means that it's very easy for a developer's machine to get out of sync with the desired configuration, and nothing automatically re-provisions the machine when the configuration is changed - a developer has to remember to re-run the provisioning step if the configuration changes.","title":"...Vagrant?"},{"location":"Comparison.html#using-shell-scripts-to-drive-docker","text":"While it's certainly possible, it quickly gets unwieldy and is difficult to effectively parallelise tasks that can run in parallel. It is also difficult to ensure that all resources created during the task, such as containers and networks, are always correctly cleaned up once the task completes, especially if the task fails.","title":"...using shell scripts to drive Docker?"},{"location":"Comparison.html#docker-compose","text":"In the past, I've used Docker Compose to implement the same idea that is at the core of batect. However, using Docker Compose for this purpose has a number of drawbacks. In particular, Docker Compose is geared towards configuring an application and its dependencies and deploying this whole stack to something like Docker Swarm. Its CLI is designed with this purpose in mind, making it frustrating to use day-to-day as a development tool and necessitating the use of a higher-level script to automate its usage. It also does not elegantly support pulling together a set of containers in different configurations (eg. integration vs journey testing), does each operation serially (instead of parallelising operations where possible) and has one long-standing bug that makes waiting for containers to report as healthy difficult.","title":"...Docker Compose?"},{"location":"Comparison.html#ci-tools-with-a-local-runner","text":"As an example, both GitLab CI and CircleCI have CLIs that allow you to run your build on your local machine, using the same containers (and therefore environment) as they do when running your build on the CI server. These tools have been designed to primarily be great CI servers, with the local CLI intended to be a convenience to allow developers to test changes to the build configuration, rather than being a day-to-day development tool. batect, on the other hand, was designed from the beginning to be a great day-to-day development tool that also works equally well on CI. Specific drawbacks of these tools compared to using batect include: batect provides a significantly better developer experience, with a simpler, easier to use CLI, clearer and more concise output (with more details available when required), and clearer error messages. One specific example would be the experience when a dependency container fails to become healthy - batect will not only tell you which container did not become healthy, but also automatically display the output from the last health check, and also provides the option to not clean up the dependency containers if they fail to allow you to investigate further. batect supports using local Dockerfiles to define the images used, rather than requiring that all images be pushed to a Docker registry. This provides a number of benefits: Additional configuration or installation of software over and above what is included in the base image can be codified in the Dockerfile, built once per machine that uses it and then cached, saving time over doing this additional configuration or installation at the beginning of each and every build. This also reduces the need to bloat the base image with configuration or software required by only one or two users of the base image, reducing their size and improving maintainability. Enabling changes to be made to the build and testing environments in the same repository as the application's code enhances traceability and understanding of why changes were made - the code change can form part of the same commit as the environmental change required to support it. These tools have only basic support for dependencies in other containers (for example, a database used for integration testing), and require the configuration of other tools such as Dockerize to ensure that dependencies are ready for use before they are used. This does not take advantage of images' built-in health checks and the benefits this mechanism has, such as a warm-up period. Furthermore, this leaves the developer to manually manage transitive dependencies between these containers, and all of the limitations with regard to the images used for the build environment discussed above apply equally to dependency images. These tools don't provide time-saving functionality such as automatically configuring proxies at image build time and in the container . As these tools are designed to run the build and only the build in exactly the same way every time, they do not support passing additional arguments to the task, making it difficult to change options for tasks that may be helpful during development, such as enabling a debugger or more verbose logging. These tools don't support easily mounting the local working copy into the build container, which means they can't be used for tasks that rely on detecting changes to code, such as a continuous unit test task. These tools don't have a way to easily codify and share tasks not used in the build but used by developers, such as a task that spins up the app with stubbed dependencies.","title":"...CI tools with a local runner?"},{"location":"GettingStarted.html","text":"Getting started tutorial \u00b6 The samples shown below are taken from the Java sample project . Installation \u00b6 Before you begin, follow the installation steps to setup batect. First steps: build environment \u00b6 To start, we're going to configure a simple build environment, where you can build your application and run unit tests. This example is for a Java project that uses Gradle, and assumes that you already have Gradle set up for your project. Create a batect.yml configuration file in the root of your project. For example: containers : build-env : image : openjdk:8u141-jdk volumes : - local : . container : /code options : cached - local : .gradle-cache container : /home/container-user/.gradle options : cached working_directory : /code environment : GRADLE_OPTS : -Dorg.gradle.daemon=false run_as_current_user : enabled : true home_directory : /home/container-user tasks : build : description : Build the application. run : container : build-env command : ./gradlew assembleDist unitTest : description : Run the unit tests. run : container : build-env command : ./gradlew test There's a bit going on here, so let's break it down: project_name : the name of your project. containers : here we define the different containers that your application needs. At the moment, we just have our one build environment container, build-env . We tell batect which Docker image to use ( image ). We tell it to mount the project ( . , the current directory) into the container at /code , and to start the container in that directory ( working_directory ). We also mount .gradle-cache into the container as /root/.gradle - this allows Gradle to cache dependencies between builds, rather than downloading them on every single run. (You probably want to add this directory to your .gitignore .) We use :cached mode for the mounts to improve performance on OS X (see this page for more information). This has no effect on other operating systems. We disable the Gradle daemon , as running it is pointless given that we create a new container for every run. We enable run as current user mode to ensure that any build artifacts are owned by you, and not root . tasks : we define our two tasks, one for building the application, and another for running the unit tests. These just run the existing Gradle tasks within the build environment we just defined. You can define whatever tasks you want - common other tasks you might like to add include one that starts a shell in the build environment (eg. one with command: bash ) and another that automatically runs the unit tests whenever the code is changed (eg. command: ./gradlew --continuous test ). For more information on batect.yml , consult the documentation . Run ./batect --list-tasks , and you'll see the tasks that we just defined: Available tasks: - build: Build the application. - unitTest: Run the unit tests. Run ./batect build and batect will pull the image used for your build environment, start it and run Gradle within it. (Note that this may take a while the first time as the Docker image must be downloaded first.) Similarly, if you run ./batect unitTest , batect will start a build environment, run your unit tests within it, and then clean up the build environment. That's it! Your builds and unit tests now run in an isolated and consistent build environment, and you can easily change the configuration of your build environment without having to install or configure anything manually on every developer or CI machine. Taking it further: integration and journey test environments \u00b6 So we've set up an isolated and repeatable build environment. However, where batect really shines is setting up integration and journey test environments - environments that require spinning up real (or fake) versions of dependencies such as databases or downstream services. Let's imagine our application just has one dependency, a Postgres database. We can define a Docker image for this with a Dockerfile: FROM postgres:9.6.2 Save this as .batect/database/Dockerfile . So far, so good - this is just like what we had before for the build environment. However, this will start an empty Postgres database, and our application probably needs at least a database and a table or two. Create a SQL script called create-structure.sql that creates your database tables and save it in the .batect/database folder you just created. We can then take advantage of a feature of the standard Postgres image to have this SQL script run when the container starts. Any .sql file in the /docker-entrypoint-initdb.d directory will automatically be run when the container starts, so if we copy our create-structure.sql script into that directory in the image, then whenever it is started, our database structure will be created. So our Dockerfile now looks like: FROM postgres:9.6.2 COPY create-structure.sql /docker-entrypoint-initdb.d/ There's one last thing we need to think about though. When Docker starts our database container, all we know is that the container has started - we have no way to know if the database is actually ready for use. If we want to run tests against our database, we don't want to start running those tests until it's actually ready to use. While Postgres is usually pretty fast to start up, it's not instantaneous, and other things can take anywhere from a few moments to a minute or two to start up and be ready. We can use Docker's health check feature to indicate when a container is ready for use. In our case, we can take the health check script from the sample project and copy it into our .batect/database folder. All it does is try to issue a simple query against the database - if that succeeds, we can assume that the database is up and running. (There's a collection of sample health check scripts provided by Docker you can use.) Then we need to tell Docker where to find our health check script, so we need to add it to our Dockerfile: FROM postgres:9.6.2 RUN mkdir -p /tools COPY health-check.sh /tools/ HEALTHCHECK --interval = 2s CMD /tools/health-check.sh COPY create-structure.sql /docker-entrypoint-initdb.d/ So, now we have a Dockerfile that describes how to start up our database, and how to tell when it's ready for use. Now we just need to configure batect to run our tests. First of all, let's define our database container: containers : ... database : build_directory : .batect/database environment : - POSTGRES_USER=international-transfers-service-user - POSTGRES_PASSWORD=TheSuperSecretPassword - POSTGRES_DB=international-transfers-service This uses the environment variables defined by the Postgres image to set the username, password and database name to use to connect to it. We could have specified them in the Dockerfile with ENV statements, but this works as well. Then we just need to define our integration test task: tasks : ... integrationTest : description : Run the integration tests. run : container : build-env command : ./gradlew integrationTest start : - database This is just like the build and unit test tasks we defined before, but we now also specify our database container in start . batect will start any containers listed in start and wait for them to become healthy before starting the container given in run . Under the covers, batect will also create an isolated network for all of the task's containers, so that they can communicate with one another without interfering with anything else on your machine. (They'll still have access to the internet and anything else they could access if they were running directly on your machine though.) This means that the integration tests just need to connect to the host database with the username international-transfers-service-user and password TheSuperSecretPassword , and Docker will automatically forward that to the database container. And, after your tests have finished, batect will then remove all the containers it started, leaving your machine in the same state it was before you started. Similarly, if we want to run some journey tests that test our application end-to-end, we just need to create a Dockerfile for our application, then define it in batect.yml : containers : ... international-transfers-service : build_directory : .batect/international-transfers-service dependencies : - database ...and then add a task: tasks : ... journeyTest : description : Run the journey tests. run : container : build-env command : ./gradlew journeyTest start : - international-transfers-service prerequisites : - build Note that in this case, we specify that the database container is a dependency of the application container - this means that batect will first start the database container and wait for it to become healthy, then start the application and wait for it to become healthy, and then run the journey tests. We also specify that the build task should run before starting the journey tests - this is so that when we start the application, we start the most recent version of it. Where next? \u00b6 There's a comprehensive reference page for the configuration file , and a number of sample applications you can take a look at.","title":"Getting started tutorial"},{"location":"GettingStarted.html#getting-started-tutorial","text":"The samples shown below are taken from the Java sample project .","title":"Getting started tutorial"},{"location":"GettingStarted.html#installation","text":"Before you begin, follow the installation steps to setup batect.","title":"Installation"},{"location":"GettingStarted.html#first-steps-build-environment","text":"To start, we're going to configure a simple build environment, where you can build your application and run unit tests. This example is for a Java project that uses Gradle, and assumes that you already have Gradle set up for your project. Create a batect.yml configuration file in the root of your project. For example: containers : build-env : image : openjdk:8u141-jdk volumes : - local : . container : /code options : cached - local : .gradle-cache container : /home/container-user/.gradle options : cached working_directory : /code environment : GRADLE_OPTS : -Dorg.gradle.daemon=false run_as_current_user : enabled : true home_directory : /home/container-user tasks : build : description : Build the application. run : container : build-env command : ./gradlew assembleDist unitTest : description : Run the unit tests. run : container : build-env command : ./gradlew test There's a bit going on here, so let's break it down: project_name : the name of your project. containers : here we define the different containers that your application needs. At the moment, we just have our one build environment container, build-env . We tell batect which Docker image to use ( image ). We tell it to mount the project ( . , the current directory) into the container at /code , and to start the container in that directory ( working_directory ). We also mount .gradle-cache into the container as /root/.gradle - this allows Gradle to cache dependencies between builds, rather than downloading them on every single run. (You probably want to add this directory to your .gitignore .) We use :cached mode for the mounts to improve performance on OS X (see this page for more information). This has no effect on other operating systems. We disable the Gradle daemon , as running it is pointless given that we create a new container for every run. We enable run as current user mode to ensure that any build artifacts are owned by you, and not root . tasks : we define our two tasks, one for building the application, and another for running the unit tests. These just run the existing Gradle tasks within the build environment we just defined. You can define whatever tasks you want - common other tasks you might like to add include one that starts a shell in the build environment (eg. one with command: bash ) and another that automatically runs the unit tests whenever the code is changed (eg. command: ./gradlew --continuous test ). For more information on batect.yml , consult the documentation . Run ./batect --list-tasks , and you'll see the tasks that we just defined: Available tasks: - build: Build the application. - unitTest: Run the unit tests. Run ./batect build and batect will pull the image used for your build environment, start it and run Gradle within it. (Note that this may take a while the first time as the Docker image must be downloaded first.) Similarly, if you run ./batect unitTest , batect will start a build environment, run your unit tests within it, and then clean up the build environment. That's it! Your builds and unit tests now run in an isolated and consistent build environment, and you can easily change the configuration of your build environment without having to install or configure anything manually on every developer or CI machine.","title":"First steps: build environment"},{"location":"GettingStarted.html#taking-it-further-integration-and-journey-test-environments","text":"So we've set up an isolated and repeatable build environment. However, where batect really shines is setting up integration and journey test environments - environments that require spinning up real (or fake) versions of dependencies such as databases or downstream services. Let's imagine our application just has one dependency, a Postgres database. We can define a Docker image for this with a Dockerfile: FROM postgres:9.6.2 Save this as .batect/database/Dockerfile . So far, so good - this is just like what we had before for the build environment. However, this will start an empty Postgres database, and our application probably needs at least a database and a table or two. Create a SQL script called create-structure.sql that creates your database tables and save it in the .batect/database folder you just created. We can then take advantage of a feature of the standard Postgres image to have this SQL script run when the container starts. Any .sql file in the /docker-entrypoint-initdb.d directory will automatically be run when the container starts, so if we copy our create-structure.sql script into that directory in the image, then whenever it is started, our database structure will be created. So our Dockerfile now looks like: FROM postgres:9.6.2 COPY create-structure.sql /docker-entrypoint-initdb.d/ There's one last thing we need to think about though. When Docker starts our database container, all we know is that the container has started - we have no way to know if the database is actually ready for use. If we want to run tests against our database, we don't want to start running those tests until it's actually ready to use. While Postgres is usually pretty fast to start up, it's not instantaneous, and other things can take anywhere from a few moments to a minute or two to start up and be ready. We can use Docker's health check feature to indicate when a container is ready for use. In our case, we can take the health check script from the sample project and copy it into our .batect/database folder. All it does is try to issue a simple query against the database - if that succeeds, we can assume that the database is up and running. (There's a collection of sample health check scripts provided by Docker you can use.) Then we need to tell Docker where to find our health check script, so we need to add it to our Dockerfile: FROM postgres:9.6.2 RUN mkdir -p /tools COPY health-check.sh /tools/ HEALTHCHECK --interval = 2s CMD /tools/health-check.sh COPY create-structure.sql /docker-entrypoint-initdb.d/ So, now we have a Dockerfile that describes how to start up our database, and how to tell when it's ready for use. Now we just need to configure batect to run our tests. First of all, let's define our database container: containers : ... database : build_directory : .batect/database environment : - POSTGRES_USER=international-transfers-service-user - POSTGRES_PASSWORD=TheSuperSecretPassword - POSTGRES_DB=international-transfers-service This uses the environment variables defined by the Postgres image to set the username, password and database name to use to connect to it. We could have specified them in the Dockerfile with ENV statements, but this works as well. Then we just need to define our integration test task: tasks : ... integrationTest : description : Run the integration tests. run : container : build-env command : ./gradlew integrationTest start : - database This is just like the build and unit test tasks we defined before, but we now also specify our database container in start . batect will start any containers listed in start and wait for them to become healthy before starting the container given in run . Under the covers, batect will also create an isolated network for all of the task's containers, so that they can communicate with one another without interfering with anything else on your machine. (They'll still have access to the internet and anything else they could access if they were running directly on your machine though.) This means that the integration tests just need to connect to the host database with the username international-transfers-service-user and password TheSuperSecretPassword , and Docker will automatically forward that to the database container. And, after your tests have finished, batect will then remove all the containers it started, leaving your machine in the same state it was before you started. Similarly, if we want to run some journey tests that test our application end-to-end, we just need to create a Dockerfile for our application, then define it in batect.yml : containers : ... international-transfers-service : build_directory : .batect/international-transfers-service dependencies : - database ...and then add a task: tasks : ... journeyTest : description : Run the journey tests. run : container : build-env command : ./gradlew journeyTest start : - international-transfers-service prerequisites : - build Note that in this case, we specify that the database container is a dependency of the application container - this means that batect will first start the database container and wait for it to become healthy, then start the application and wait for it to become healthy, and then run the journey tests. We also specify that the build task should run before starting the journey tests - this is so that when we start the application, we start the most recent version of it.","title":"Taking it further: integration and journey test environments"},{"location":"GettingStarted.html#where-next","text":"There's a comprehensive reference page for the configuration file , and a number of sample applications you can take a look at.","title":"Where next?"},{"location":"QuickStart.html","text":"Quick start \u00b6 The batect script is designed to be committed alongside your project, and not installed globally. It will automatically pull down the correct version of batect for your operating system. Download the latest version of batect from the releases page , and copy it into your project. Note that you only need the file named batect - you don't need to download batect.jar . Make sure it's executable (run chmod +x batect ). Run ./batect --version and if you see some version information, you're good to go! Note that a JVM (version 8 or above) must be installed to use batect. (This requirement will be removed in a future release.) batect is compatible with Docker 17.06 and higher. Now you're ready to configure batect for your project - check out the getting started tutorial , dive into the configuration file reference , or take a look at one of the sample projects .","title":"Quick start"},{"location":"QuickStart.html#quick-start","text":"The batect script is designed to be committed alongside your project, and not installed globally. It will automatically pull down the correct version of batect for your operating system. Download the latest version of batect from the releases page , and copy it into your project. Note that you only need the file named batect - you don't need to download batect.jar . Make sure it's executable (run chmod +x batect ). Run ./batect --version and if you see some version information, you're good to go! Note that a JVM (version 8 or above) must be installed to use batect. (This requirement will be removed in a future release.) batect is compatible with Docker 17.06 and higher. Now you're ready to configure batect for your project - check out the getting started tutorial , dive into the configuration file reference , or take a look at one of the sample projects .","title":"Quick start"},{"location":"SampleProjects.html","text":"Sample projects \u00b6 There are a number of projects that demonstrate the use of batect: batect-sample-golang : demonstrates a setup for Golang and Circle CI batect-sample-java : demonstrates a setup for Java, Gradle, Travis CI and pushing images to Docker Hub batect-sample-ruby : demonstrates a setup for Ruby and Travis CI weekly-meetups : demonstrates a setup for Clojure and Leiningen The batect codebase itself also contains an example of running both Elasticsearch and Kibana (this is used to view and query log files generated at runtime by batect).","title":"Sample projects"},{"location":"SampleProjects.html#sample-projects","text":"There are a number of projects that demonstrate the use of batect: batect-sample-golang : demonstrates a setup for Golang and Circle CI batect-sample-java : demonstrates a setup for Java, Gradle, Travis CI and pushing images to Docker Hub batect-sample-ruby : demonstrates a setup for Ruby and Travis CI weekly-meetups : demonstrates a setup for Clojure and Leiningen The batect codebase itself also contains an example of running both Elasticsearch and Kibana (this is used to view and query log files generated at runtime by batect).","title":"Sample projects"},{"location":"config/Containers.html","text":"Container definitions \u00b6 Each container definition is made up of: image \u00b6 Image name (in standard Docker image reference format) to use for this container. One of image or build_directory is required. Tip It is highly recommended that you specify a specific image version, and not use latest , to ensure that the same image is used everywhere. For example, use alpine:3.7 , not alpine or alpine:latest . build_directory \u00b6 Path (relative to the configuration file's directory) to a directory containing a Dockerfile to build and use as an image for this container. One of image or build_directory is required. build_args \u00b6 List of build args (in name: value format) to use when building the image in build_directory . Each build arg must be defined in the Dockerfile with an ARG instruction otherwise the value provided will have no effect. The value of environment variables from the host can be passed as build args using the same syntax as for environment . Warning Use caution when using build args for secret values. Build arg values can be revealed by anyone with a copy of the image with the docker history command. Available since v0.28. The ability to use environment variable values in build args was added in v0.32. dockerfile \u00b6 Dockerfile (relative to build_directory ) to use when building the image in build_directory . Defaults to Dockerfile if not set. The Dockerfile must be within build_directory . Available since v0.31. command \u00b6 Command to run when the container starts. If not provided, the default command for the image will be run. Both of these can be overridden for an individual task by specifying a command at the task level . Note Keep in mind that this command is passed to the image's ENTRYPOINT , just like it would when using docker run <image> <command> directly. This means that if the entrypoint is not set or is not a shell, standard shell syntax features like && might not work. See the Docker docs for CMD and ENTRYPOINT for more details. If you would like to use shell syntax features in your command, you have two options: Set the entrypoint in the image to a shell. For example: ENTRYPOINT [ \"/bin/sh\" , \"-c\" ] Wrap your command in a shell invocation. For example, if your command is echo hello && echo world , set command to sh -c 'echo hello && echo world' . environment \u00b6 List of environment variables (in name: value format) for the container. Prior to v0.21, environment variables were required to be supplied in name=value format. Environment variable substitution \u00b6 You can pass environment variables from the host (ie. where you run batect) to the container by using any of the following formats: $<name> or ${<name>} : use the value of <name> from the host as the value inside the container. If the referenced host variable is not present, batect will show an error message and not start the task. ${<name>:-<default>} : use the value of <name> from the host as the value inside the container. If the referenced host variable is not present, <default> is used instead. <default> can be empty, so ${<name>:-} will use the value of <name> from the host if it is set, or a blank value if it is not set. For example, to set SUPER_SECRET_PASSWORD in the container to the value of the MY_PASSWORD variable on the host, use SUPER_SECRET_PASSWORD: $MY_PASSWORD or SUPER_SECRET_PASSWORD: ${MY_PASSWORD} . Or, to default it to insecure if MY_PASSWORD is not set, use SUPER_SECRET_PASSWORD: ${MY_PASSWORD:-insecure} . Substitution in the middle of values is not supported (eg. SUPER_SECRET_PASSWORD: My password is $MY_PASSWORD will not work). Warning Be careful when using this - by relying on the host's environment variables, you are introducing inconsistency to how the container runs between hosts, which is something you generally want to avoid. The curly brace syntax for environment variables, including the ability to specify default values for environment variables, was added in v0.21. TERM \u00b6 The TERM environment variable, if set on the host, is always automatically passed through to the container. This ensures that features such as coloured output continue to work correctly inside the container. Proxy-related environment variables \u00b6 Proxy-related environment variables, if set on the host, are passed through to the container at build and run time, but are not used for image pulls. If a proxy-related environment variable is defined on the container's configuration, it takes precedence over the host-provided value. See this page for more information on using batect with proxies. working_directory \u00b6 Working directory to start the container in. If not provided, the default working directory for the image will be used. Both of these can be overridden for an individual task by specifying a working_directory at the task level . volumes \u00b6 List of volume mounts to create for the container. Relative local paths will be resolved relative to the configuration file's directory. Two formats are supported: Standard Docker local:container or local:container:mode format An expanded format: containers : my-container : ... volumes : # This is equivalent to .:/code:cached - local : . container : /code options : cached See this page for more information on why using cached volume mounts may be worthwhile. ports \u00b6 List of ports to make available to the host machine. Only TCP ports are supported at present. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in the http-server container listens on port 2000, any other container in the task can access that at http-server:2000 without port 2000 being listed in ports (or an EXPOSE Dockerfile instruction). Two formats are supported: Standard Docker local:container format. For example, 1234:5678 will make port 5678 inside the container available on the host machine at port 1234. An expanded format: containers : my-container : ... ports : # This is equivalent to 1234:5678 - local : 1234 container : 5678 dependencies \u00b6 List of other containers that should be started and healthy before starting this container. If a dependency's image does not contain a health check , then as soon as it has started, it is considered to be healthy. See this page for more information on how to ensure dependencies are ready before starting containers that depend on them. health_check \u00b6 Overrides health check configuration specified in the image or Dockerfile: retries The number of times to perform the health check before considering the container unhealthy. interval The interval between runs of the health check. Accepts values such as 2s (two seconds) or 1m (one minute). start_period The time to wait before failing health checks count against the retry count. The health check is still run during this period, and if the check succeeds, the container is immediately considered healthy. Accepts values such as 2s (two seconds) or 1m (one minute). run_as_current_user \u00b6 Run the container with the same UID and GID as the user running batect (rather than the user the Docker daemon runs as, which is root on Linux). This means that any files created by the container will be owned by the user running batect, rather than root. This is really only useful on Linux. On OS X, the Docker daemon runs as the currently logged-in user and so any files created in the container are owned by that user, so this is less of an issue. However, for consistency, the same configuration changes are made on both Linux and OS X. run_as_current_user has the following options: enabled Defaults to false , set to true to enable 'run as current user' mode. home_directory Directory to use as home directory for user inside container. Required if enabled is true , not allowed if enabled is not provided or set to false . This directory is automatically created by batect with the correct owner and group. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. See this page for more information on the effects of this option and why it is necessary. privileged \u00b6 Set to true to run the container in privileged mode . See also capabilities_to_add and capabilities_to_drop . Available since v0.29. capabilities_to_add and capabilities_to_drop \u00b6 List of capabilities to add or drop for the container. This is equivalent to passing --cap-add or --cap-drop to docker run . Available since v0.31. enable_init_process \u00b6 Set to true to pass the --init flag when running the container. This creates the container with a simple PID 1 process to handle the responsibilities of the init system, which is required for some applications to behave correctly. Read this article if you're interested in more information about the behaviour of different processes running as PID 1 and why this flag was introduced. Available since v0.30. Examples \u00b6 For more examples and real-world scenarios, take a look at the sample projects . Minimal configuration with existing image \u00b6 containers : build-env : image : openjdk:8u141-jdk Running the container build-env will launch a container that uses the openjdk:8u141-jdk image. If the image has not already been pulled, batect will pull it before starting the container. Minimal configuration with Dockerfile \u00b6 containers : build-env : build_directory : .batect/build-env Running the container build-env will first build the Dockerfile in the .batect/build-env directory, then run the resulting image. The Docker build cache is used during the build process, so if the image definition has not changed since the last build, the image will not be rebuilt, saving time. Container with custom command \u00b6 containers : build-env : image : ruby:2.4.3 command : echo 'Hello world' Running the container build-env will run the command echo 'Hello world' , and not the default command specified in the ruby:2.4.3 image. This command could, however, be overridden by specifying a command at the task level . Container with environment variables \u00b6 containers : build-env : image : ruby:2.4.3 environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD ANOTHER_SECRET_VALUE : ${SECRET_PASSWORD} OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the container build-env will launch a container that uses the ruby:2.4.3 image with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variables SUPER_SECRET_VALUE and ANOTHER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container. These environment variables could be overridden (and added to) with environment at the task level . Container with working directory \u00b6 containers : build-env : image : ruby:2.4.3 working_directory : /somewhere Running the container build-env will launch a container that uses the ruby:2.4.3 image with the working directory set to /somewhere . Container with volume mounts \u00b6 containers : build-env : image : ruby:2.4.3 volumes : - local : . container : /code options : cached Running the container build-env will launch a container that uses the ruby:2.4.3 image, with the directory containing the batect configuration file mounted into the container at /code . For example, if the batect configuration file is on the host at /home/alice/code/my-project/batect.yml , then /home/alice/code/my-project will be available inside the container at /code . See this page for more information on why using cached volume mounts may be worthwhile. Container with ports \u00b6 containers : build-env : image : ruby:2.4.3 ports : - local : 123 container : 456 Running the container build-env will launch a container that uses the ruby:2.4.3 image, with the port 123 on the host mapped to port 456 inside the container. For example, this means that if a web server is listening on port 456 within the container, it can be accessed from the host at http://localhost:123 . The Dockerfile for the ruby:2.4.3 image does not need to contain an EXPOSE instruction for port 456. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other, just how they're exposed to the host. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in another container wants to access the application running on port 456 in the build-env container, it would access it at build-env:456 , not build-env:123 . Container with dependencies \u00b6 containers : application : build_directory : .batect/application dependencies : - database database : build_directory : .batect/database Running the container application will first run the database container and wait for it to become healthy before starting the application container. Container that runs as the current user \u00b6 containers : build-env : image : ruby:2.4.3 run_as_current_user : enabled : true home_directory : /home/container-user Running the container build-env will launch a container that uses the ruby:2.4.3 image with run as current user mode enabled. Container that runs with a Docker's default init process enabled \u00b6 containers : build-env : image : node:10.10.0-alpine volumes : - local : . container : /code options : cached enable_init_process : true Running the container build-env will launch a container that uses the node:10.10.0-alpine image with Docker's default init process as PID 1.","title":"Containers"},{"location":"config/Containers.html#container-definitions","text":"Each container definition is made up of:","title":"Container definitions"},{"location":"config/Containers.html#image","text":"Image name (in standard Docker image reference format) to use for this container. One of image or build_directory is required. Tip It is highly recommended that you specify a specific image version, and not use latest , to ensure that the same image is used everywhere. For example, use alpine:3.7 , not alpine or alpine:latest .","title":"image"},{"location":"config/Containers.html#build_directory","text":"Path (relative to the configuration file's directory) to a directory containing a Dockerfile to build and use as an image for this container. One of image or build_directory is required.","title":"build_directory"},{"location":"config/Containers.html#build_args","text":"List of build args (in name: value format) to use when building the image in build_directory . Each build arg must be defined in the Dockerfile with an ARG instruction otherwise the value provided will have no effect. The value of environment variables from the host can be passed as build args using the same syntax as for environment . Warning Use caution when using build args for secret values. Build arg values can be revealed by anyone with a copy of the image with the docker history command. Available since v0.28. The ability to use environment variable values in build args was added in v0.32.","title":"build_args"},{"location":"config/Containers.html#dockerfile","text":"Dockerfile (relative to build_directory ) to use when building the image in build_directory . Defaults to Dockerfile if not set. The Dockerfile must be within build_directory . Available since v0.31.","title":"dockerfile"},{"location":"config/Containers.html#command","text":"Command to run when the container starts. If not provided, the default command for the image will be run. Both of these can be overridden for an individual task by specifying a command at the task level . Note Keep in mind that this command is passed to the image's ENTRYPOINT , just like it would when using docker run <image> <command> directly. This means that if the entrypoint is not set or is not a shell, standard shell syntax features like && might not work. See the Docker docs for CMD and ENTRYPOINT for more details. If you would like to use shell syntax features in your command, you have two options: Set the entrypoint in the image to a shell. For example: ENTRYPOINT [ \"/bin/sh\" , \"-c\" ] Wrap your command in a shell invocation. For example, if your command is echo hello && echo world , set command to sh -c 'echo hello && echo world' .","title":"command"},{"location":"config/Containers.html#environment","text":"List of environment variables (in name: value format) for the container. Prior to v0.21, environment variables were required to be supplied in name=value format.","title":"environment"},{"location":"config/Containers.html#environment-variable-substitution","text":"You can pass environment variables from the host (ie. where you run batect) to the container by using any of the following formats: $<name> or ${<name>} : use the value of <name> from the host as the value inside the container. If the referenced host variable is not present, batect will show an error message and not start the task. ${<name>:-<default>} : use the value of <name> from the host as the value inside the container. If the referenced host variable is not present, <default> is used instead. <default> can be empty, so ${<name>:-} will use the value of <name> from the host if it is set, or a blank value if it is not set. For example, to set SUPER_SECRET_PASSWORD in the container to the value of the MY_PASSWORD variable on the host, use SUPER_SECRET_PASSWORD: $MY_PASSWORD or SUPER_SECRET_PASSWORD: ${MY_PASSWORD} . Or, to default it to insecure if MY_PASSWORD is not set, use SUPER_SECRET_PASSWORD: ${MY_PASSWORD:-insecure} . Substitution in the middle of values is not supported (eg. SUPER_SECRET_PASSWORD: My password is $MY_PASSWORD will not work). Warning Be careful when using this - by relying on the host's environment variables, you are introducing inconsistency to how the container runs between hosts, which is something you generally want to avoid. The curly brace syntax for environment variables, including the ability to specify default values for environment variables, was added in v0.21.","title":"Environment variable substitution"},{"location":"config/Containers.html#term","text":"The TERM environment variable, if set on the host, is always automatically passed through to the container. This ensures that features such as coloured output continue to work correctly inside the container.","title":"TERM"},{"location":"config/Containers.html#proxy-related-environment-variables","text":"Proxy-related environment variables, if set on the host, are passed through to the container at build and run time, but are not used for image pulls. If a proxy-related environment variable is defined on the container's configuration, it takes precedence over the host-provided value. See this page for more information on using batect with proxies.","title":"Proxy-related environment variables"},{"location":"config/Containers.html#working_directory","text":"Working directory to start the container in. If not provided, the default working directory for the image will be used. Both of these can be overridden for an individual task by specifying a working_directory at the task level .","title":"working_directory"},{"location":"config/Containers.html#volumes","text":"List of volume mounts to create for the container. Relative local paths will be resolved relative to the configuration file's directory. Two formats are supported: Standard Docker local:container or local:container:mode format An expanded format: containers : my-container : ... volumes : # This is equivalent to .:/code:cached - local : . container : /code options : cached See this page for more information on why using cached volume mounts may be worthwhile.","title":"volumes"},{"location":"config/Containers.html#ports","text":"List of ports to make available to the host machine. Only TCP ports are supported at present. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in the http-server container listens on port 2000, any other container in the task can access that at http-server:2000 without port 2000 being listed in ports (or an EXPOSE Dockerfile instruction). Two formats are supported: Standard Docker local:container format. For example, 1234:5678 will make port 5678 inside the container available on the host machine at port 1234. An expanded format: containers : my-container : ... ports : # This is equivalent to 1234:5678 - local : 1234 container : 5678","title":"ports"},{"location":"config/Containers.html#dependencies","text":"List of other containers that should be started and healthy before starting this container. If a dependency's image does not contain a health check , then as soon as it has started, it is considered to be healthy. See this page for more information on how to ensure dependencies are ready before starting containers that depend on them.","title":"dependencies"},{"location":"config/Containers.html#health_check","text":"Overrides health check configuration specified in the image or Dockerfile: retries The number of times to perform the health check before considering the container unhealthy. interval The interval between runs of the health check. Accepts values such as 2s (two seconds) or 1m (one minute). start_period The time to wait before failing health checks count against the retry count. The health check is still run during this period, and if the check succeeds, the container is immediately considered healthy. Accepts values such as 2s (two seconds) or 1m (one minute).","title":"health_check"},{"location":"config/Containers.html#run_as_current_user","text":"Run the container with the same UID and GID as the user running batect (rather than the user the Docker daemon runs as, which is root on Linux). This means that any files created by the container will be owned by the user running batect, rather than root. This is really only useful on Linux. On OS X, the Docker daemon runs as the currently logged-in user and so any files created in the container are owned by that user, so this is less of an issue. However, for consistency, the same configuration changes are made on both Linux and OS X. run_as_current_user has the following options: enabled Defaults to false , set to true to enable 'run as current user' mode. home_directory Directory to use as home directory for user inside container. Required if enabled is true , not allowed if enabled is not provided or set to false . This directory is automatically created by batect with the correct owner and group. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. See this page for more information on the effects of this option and why it is necessary.","title":"run_as_current_user"},{"location":"config/Containers.html#privileged","text":"Set to true to run the container in privileged mode . See also capabilities_to_add and capabilities_to_drop . Available since v0.29.","title":"privileged"},{"location":"config/Containers.html#capabilities_to_add-and-capabilities_to_drop","text":"List of capabilities to add or drop for the container. This is equivalent to passing --cap-add or --cap-drop to docker run . Available since v0.31.","title":"capabilities_to_add and capabilities_to_drop"},{"location":"config/Containers.html#enable_init_process","text":"Set to true to pass the --init flag when running the container. This creates the container with a simple PID 1 process to handle the responsibilities of the init system, which is required for some applications to behave correctly. Read this article if you're interested in more information about the behaviour of different processes running as PID 1 and why this flag was introduced. Available since v0.30.","title":"enable_init_process"},{"location":"config/Containers.html#examples","text":"For more examples and real-world scenarios, take a look at the sample projects .","title":"Examples"},{"location":"config/Containers.html#minimal-configuration-with-existing-image","text":"containers : build-env : image : openjdk:8u141-jdk Running the container build-env will launch a container that uses the openjdk:8u141-jdk image. If the image has not already been pulled, batect will pull it before starting the container.","title":"Minimal configuration with existing image"},{"location":"config/Containers.html#minimal-configuration-with-dockerfile","text":"containers : build-env : build_directory : .batect/build-env Running the container build-env will first build the Dockerfile in the .batect/build-env directory, then run the resulting image. The Docker build cache is used during the build process, so if the image definition has not changed since the last build, the image will not be rebuilt, saving time.","title":"Minimal configuration with Dockerfile"},{"location":"config/Containers.html#container-with-custom-command","text":"containers : build-env : image : ruby:2.4.3 command : echo 'Hello world' Running the container build-env will run the command echo 'Hello world' , and not the default command specified in the ruby:2.4.3 image. This command could, however, be overridden by specifying a command at the task level .","title":"Container with custom command"},{"location":"config/Containers.html#container-with-environment-variables","text":"containers : build-env : image : ruby:2.4.3 environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD ANOTHER_SECRET_VALUE : ${SECRET_PASSWORD} OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the container build-env will launch a container that uses the ruby:2.4.3 image with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variables SUPER_SECRET_VALUE and ANOTHER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container. These environment variables could be overridden (and added to) with environment at the task level .","title":"Container with environment variables"},{"location":"config/Containers.html#container-with-working-directory","text":"containers : build-env : image : ruby:2.4.3 working_directory : /somewhere Running the container build-env will launch a container that uses the ruby:2.4.3 image with the working directory set to /somewhere .","title":"Container with working directory"},{"location":"config/Containers.html#container-with-volume-mounts","text":"containers : build-env : image : ruby:2.4.3 volumes : - local : . container : /code options : cached Running the container build-env will launch a container that uses the ruby:2.4.3 image, with the directory containing the batect configuration file mounted into the container at /code . For example, if the batect configuration file is on the host at /home/alice/code/my-project/batect.yml , then /home/alice/code/my-project will be available inside the container at /code . See this page for more information on why using cached volume mounts may be worthwhile.","title":"Container with volume mounts"},{"location":"config/Containers.html#container-with-ports","text":"containers : build-env : image : ruby:2.4.3 ports : - local : 123 container : 456 Running the container build-env will launch a container that uses the ruby:2.4.3 image, with the port 123 on the host mapped to port 456 inside the container. For example, this means that if a web server is listening on port 456 within the container, it can be accessed from the host at http://localhost:123 . The Dockerfile for the ruby:2.4.3 image does not need to contain an EXPOSE instruction for port 456. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other, just how they're exposed to the host. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in another container wants to access the application running on port 456 in the build-env container, it would access it at build-env:456 , not build-env:123 .","title":"Container with ports"},{"location":"config/Containers.html#container-with-dependencies","text":"containers : application : build_directory : .batect/application dependencies : - database database : build_directory : .batect/database Running the container application will first run the database container and wait for it to become healthy before starting the application container.","title":"Container with dependencies"},{"location":"config/Containers.html#container-that-runs-as-the-current-user","text":"containers : build-env : image : ruby:2.4.3 run_as_current_user : enabled : true home_directory : /home/container-user Running the container build-env will launch a container that uses the ruby:2.4.3 image with run as current user mode enabled.","title":"Container that runs as the current user"},{"location":"config/Containers.html#container-that-runs-with-a-dockers-default-init-process-enabled","text":"containers : build-env : image : node:10.10.0-alpine volumes : - local : . container : /code options : cached enable_init_process : true Running the container build-env will launch a container that uses the node:10.10.0-alpine image with Docker's default init process as PID 1.","title":"Container that runs with a Docker's default init process enabled"},{"location":"config/Overview.html","text":"Configuration file overview \u00b6 batect uses a YAML-based configuration file. By convention, this file is called batect.yml and is placed in the root of your project (alongside the batect script). You can, however, use a different name or location, and tell batect where to find it with the -f option. The root of the configuration file is made up of: project_name \u00b6 The name of your project. Used to label any images built. If a project name is not provided, the project name is taken from the directory containing the configuration file. For example, if your configuration file is /home/alex/projects/my-cool-app/batect.yml and you do not provide a project name, my-cool-app will be used automatically. Project names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores containers \u00b6 Definitions for each of the containers that make up your various environments, in name: options format. Container names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores Detailed reference for containers tasks \u00b6 Definitions for each of your tasks, the actions you launch through batect, in name: options format. Detailed reference for tasks Anchors, aliases, extensions and merging \u00b6 Available since v0.27. batect supports YAML anchors and aliases. This allows you to specify a value in one place, and refer to it elsewhere. For example: somewhere : &value-used-multiple-times the-value # This is equivalent to somewhere-else: the-value somewhere-else : *value-used-multiple-times Anchors ( &... ) must be defined before they are referenced with an alias ( *... ). batect also supports extensions, which behave in an identical way, but allow you to define values before you use it for the first time. The following is equivalent to the example above: .value-used-multiple-times : &value-used-multiple-times the-value somewhere : *value-used-multiple-times somewhere-else : *value-used-multiple-times Extensions must be defined at the root level of your configuration file, and the key must start with a period ( . ). batect also supports the merge operator ( << ) in maps. For example: .common-environment : &common-environment ENABLE_COOL_FEATURE : true DATABASE_HOST : postgres:1234 tasks : run-app : run : ... environment : *common-environment # Just uses the values in common-environment as-is run-app-without-cool-feature : run : ... environment : << : *common-environment # Use common-environment as the basis for the environment in this task... ENABLE_COOL_FEATURE : false # ...but override the value of ENABLE_COOL_FEATURE You can merge a single map with <<: *other-map , or multiple maps with <<: [ *map-1, *map-2 ] . Local values take precedence over values merged into a map (regardless of the position of the << entry), and values from sources earlier in the list of maps take precedence over values from later sources. (For example, if both map-1 and map-2 define a value for PORT in the example earlier, the value in map-1 is used.) Examples \u00b6 Examples are provided in the reference for containers and tasks . For further examples and real-world scenarios, take a look at the sample projects .","title":"Overview"},{"location":"config/Overview.html#configuration-file-overview","text":"batect uses a YAML-based configuration file. By convention, this file is called batect.yml and is placed in the root of your project (alongside the batect script). You can, however, use a different name or location, and tell batect where to find it with the -f option. The root of the configuration file is made up of:","title":"Configuration file overview"},{"location":"config/Overview.html#project_name","text":"The name of your project. Used to label any images built. If a project name is not provided, the project name is taken from the directory containing the configuration file. For example, if your configuration file is /home/alex/projects/my-cool-app/batect.yml and you do not provide a project name, my-cool-app will be used automatically. Project names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores","title":"project_name"},{"location":"config/Overview.html#containers","text":"Definitions for each of the containers that make up your various environments, in name: options format. Container names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores Detailed reference for containers","title":"containers"},{"location":"config/Overview.html#tasks","text":"Definitions for each of your tasks, the actions you launch through batect, in name: options format. Detailed reference for tasks","title":"tasks"},{"location":"config/Overview.html#anchors-aliases-extensions-and-merging","text":"Available since v0.27. batect supports YAML anchors and aliases. This allows you to specify a value in one place, and refer to it elsewhere. For example: somewhere : &value-used-multiple-times the-value # This is equivalent to somewhere-else: the-value somewhere-else : *value-used-multiple-times Anchors ( &... ) must be defined before they are referenced with an alias ( *... ). batect also supports extensions, which behave in an identical way, but allow you to define values before you use it for the first time. The following is equivalent to the example above: .value-used-multiple-times : &value-used-multiple-times the-value somewhere : *value-used-multiple-times somewhere-else : *value-used-multiple-times Extensions must be defined at the root level of your configuration file, and the key must start with a period ( . ). batect also supports the merge operator ( << ) in maps. For example: .common-environment : &common-environment ENABLE_COOL_FEATURE : true DATABASE_HOST : postgres:1234 tasks : run-app : run : ... environment : *common-environment # Just uses the values in common-environment as-is run-app-without-cool-feature : run : ... environment : << : *common-environment # Use common-environment as the basis for the environment in this task... ENABLE_COOL_FEATURE : false # ...but override the value of ENABLE_COOL_FEATURE You can merge a single map with <<: *other-map , or multiple maps with <<: [ *map-1, *map-2 ] . Local values take precedence over values merged into a map (regardless of the position of the << entry), and values from sources earlier in the list of maps take precedence over values from later sources. (For example, if both map-1 and map-2 define a value for PORT in the example earlier, the value in map-1 is used.)","title":"Anchors, aliases, extensions and merging"},{"location":"config/Overview.html#examples","text":"Examples are provided in the reference for containers and tasks . For further examples and real-world scenarios, take a look at the sample projects .","title":"Examples"},{"location":"config/Tasks.html","text":"Task definitions \u00b6 Each task definition is made up of: description \u00b6 Description shown when running batect --list-tasks . group \u00b6 Group name used to group tasks when running batect --list-tasks . Available since v0.27. run \u00b6 Specifies what to do when this task starts: container Container to run for this task. Required. command Command to run for this task. Overrides any command specified on the container definition and the image's default command. If no command is provided here, the command specified on the container definition is used if there is one, otherwise the image's default command is used. Just like when specifying a command for a container, this command is passed to the image's ENTRYPOINT , if there is one. This can prevent shell syntax features like && from working. See the note about entrypoints in the documentation for containers for more information. environment List of environment variables (in name: value format) to pass to the container, in addition to those defined on the container itself. If a variable is specified both here and on the container itself, the value given here will override the value defined on the container. This field supports all of the same syntax as when specifying a variable directly on the container , including passing variables from the host to the container and providing defaults for when the host variable is not set. Prior to v0.21, environment variables were required to be supplied in name=value format. ports List of port mappings to create for the container, in addition to those defined on the container itself. Behaves identically to specifying a port mapping directly on the container , and supports the same syntax. Available since v0.13. working_directory Working directory to use for this task's container. Overrides any working directory on the container definition and the image's default working directory. If no working directory is provided here, the working directory specified on the container definition is used if there is one, otherwise the image's default working directory is used. Available since v0.26. dependencies \u00b6 List of other containers that should be started and healthy before starting the task container given in run . The behaviour is the same as if the dependencies were specified for the dependencies property of the task's container's definition. prerequisites \u00b6 List of other tasks that should be run before running this task. If a prerequisite task finishes with a non-zero exit code, then neither this task nor any other prerequisites will be run. The tasks are run in the same order that they are declared in, unless reordering is required to satisfy the prerequisites of of of this task's prerequisites. Examples \u00b6 For more examples and real-world scenarios, take a look at the sample projects . Minimal configuration \u00b6 tasks : start-app : run : container : app Running the task start-app will start the app container. The container will run the command provided in the container configuration (or the default command in the image if there is no command given for the container definition). Task with prerequisites \u00b6 tasks : build : run : container : build-env command : build.sh start-app : run : container : app prerequisites : - build Running the task start-app will first run the build task (which runs build.sh in the build-env container), and then run the app container. If the command build.sh exits with a non-zero exit code, start-app will not be run. Task with dependencies \u00b6 tasks : start-app : run : container : app dependencies : - database - auth-service-fake Running the task start-app will do the following: Build or pull the images for the app , database and auth-service-fake containers, as appropriate Start the database and auth-service-fake containers Wait for the database and auth-service-fake containers to report themselves as healthy ( if they have health checks defined ) Start the app container Task with environment variables \u00b6 tasks : start-app : run : container : app environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD ANOTHER_SECRET_VALUE : ${SECRET_PASSWORD} OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the task start-app will start the app container with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variables SUPER_SECRET_VALUE and ANOTHER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container. Task with port mappings \u00b6 tasks : start-app : run : container : app ports : - 123:456 - local : 1000 container : 2000 Running the task start-app will start the app container with the following port mappings defined: Port 123 on the host will be mapped to port 456 inside the container Port 1000 on the host will be mapped to port 2000 inside the container For example, this means that if a web server is listening on port 456 within the container, it can be accessed from the host at http://localhost:123 . The Dockerfile for the image used by the app container does not need to contain an EXPOSE instruction for ports 456 or 2000. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other, just how they're exposed to the host. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in another container wants to access the application running on port 456 in the app container, it would access it at app:456 , not app:123 .","title":"Tasks"},{"location":"config/Tasks.html#task-definitions","text":"Each task definition is made up of:","title":"Task definitions"},{"location":"config/Tasks.html#description","text":"Description shown when running batect --list-tasks .","title":"description"},{"location":"config/Tasks.html#group","text":"Group name used to group tasks when running batect --list-tasks . Available since v0.27.","title":"group"},{"location":"config/Tasks.html#run","text":"Specifies what to do when this task starts: container Container to run for this task. Required. command Command to run for this task. Overrides any command specified on the container definition and the image's default command. If no command is provided here, the command specified on the container definition is used if there is one, otherwise the image's default command is used. Just like when specifying a command for a container, this command is passed to the image's ENTRYPOINT , if there is one. This can prevent shell syntax features like && from working. See the note about entrypoints in the documentation for containers for more information. environment List of environment variables (in name: value format) to pass to the container, in addition to those defined on the container itself. If a variable is specified both here and on the container itself, the value given here will override the value defined on the container. This field supports all of the same syntax as when specifying a variable directly on the container , including passing variables from the host to the container and providing defaults for when the host variable is not set. Prior to v0.21, environment variables were required to be supplied in name=value format. ports List of port mappings to create for the container, in addition to those defined on the container itself. Behaves identically to specifying a port mapping directly on the container , and supports the same syntax. Available since v0.13. working_directory Working directory to use for this task's container. Overrides any working directory on the container definition and the image's default working directory. If no working directory is provided here, the working directory specified on the container definition is used if there is one, otherwise the image's default working directory is used. Available since v0.26.","title":"run"},{"location":"config/Tasks.html#dependencies","text":"List of other containers that should be started and healthy before starting the task container given in run . The behaviour is the same as if the dependencies were specified for the dependencies property of the task's container's definition.","title":"dependencies"},{"location":"config/Tasks.html#prerequisites","text":"List of other tasks that should be run before running this task. If a prerequisite task finishes with a non-zero exit code, then neither this task nor any other prerequisites will be run. The tasks are run in the same order that they are declared in, unless reordering is required to satisfy the prerequisites of of of this task's prerequisites.","title":"prerequisites"},{"location":"config/Tasks.html#examples","text":"For more examples and real-world scenarios, take a look at the sample projects .","title":"Examples"},{"location":"config/Tasks.html#minimal-configuration","text":"tasks : start-app : run : container : app Running the task start-app will start the app container. The container will run the command provided in the container configuration (or the default command in the image if there is no command given for the container definition).","title":"Minimal configuration"},{"location":"config/Tasks.html#task-with-prerequisites","text":"tasks : build : run : container : build-env command : build.sh start-app : run : container : app prerequisites : - build Running the task start-app will first run the build task (which runs build.sh in the build-env container), and then run the app container. If the command build.sh exits with a non-zero exit code, start-app will not be run.","title":"Task with prerequisites"},{"location":"config/Tasks.html#task-with-dependencies","text":"tasks : start-app : run : container : app dependencies : - database - auth-service-fake Running the task start-app will do the following: Build or pull the images for the app , database and auth-service-fake containers, as appropriate Start the database and auth-service-fake containers Wait for the database and auth-service-fake containers to report themselves as healthy ( if they have health checks defined ) Start the app container","title":"Task with dependencies"},{"location":"config/Tasks.html#task-with-environment-variables","text":"tasks : start-app : run : container : app environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD ANOTHER_SECRET_VALUE : ${SECRET_PASSWORD} OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the task start-app will start the app container with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variables SUPER_SECRET_VALUE and ANOTHER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container.","title":"Task with environment variables"},{"location":"config/Tasks.html#task-with-port-mappings","text":"tasks : start-app : run : container : app ports : - 123:456 - local : 1000 container : 2000 Running the task start-app will start the app container with the following port mappings defined: Port 123 on the host will be mapped to port 456 inside the container Port 1000 on the host will be mapped to port 2000 inside the container For example, this means that if a web server is listening on port 456 within the container, it can be accessed from the host at http://localhost:123 . The Dockerfile for the image used by the app container does not need to contain an EXPOSE instruction for ports 456 or 2000. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other, just how they're exposed to the host. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in another container wants to access the application running on port 456 in the app container, it would access it at app:456 , not app:123 .","title":"Task with port mappings"},{"location":"tips/BuildArtifactsOwnedByRoot.html","text":"Build artifacts are owned by root \u00b6 tl;dr If a container produces build artifacts in a mounted volume, enable run_as_current_user , otherwise they'll be owned by the root Unix user On Linux, by default, the Docker daemon runs as root, and so all containers run as root. This means that when a container writes a file to a mounted volume, it is owned by the root Unix user, making it difficult for other users to modify or delete the files. This most often comes up when a build task produces an artifact and writes that artifact to a mounted volume. (On OS X, the Docker daemon runs as the currently logged-in user and so any files created in mounted volumes are owned by that user, so this is not an issue.) To fix this issue, batect can run containers in 'run as current user' mode, ensuring that all files written to a mounted volume are created by the current user, not root. This mode can be enabled on a per-container basis with the run_as_current_user option . When enabled, the following configuration changes are made: The container is run with the current user's UID and GID (equivalent to passing --user $(id -u):$(id -g) to docker run ) An empty directory is mounted into the container at home_directory for the user's home directory. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. A new /etc/passwd file is mounted into the container with two users: root and the current user. The current user's home directory is set to the value of home_directory . (If batect is running as root, then just root is listed and it takes the home directory provided in home_directory .) This means that any other users defined in the container's image are effectively lost. Under most circumstances, this is not an issue. Similarly, a new /etc/group file is mounted into the container with two groups: root and the current user's primary group (usually staff on OS X, and the user's name on Linux). If batect is running as root, then just root is listed. Again, this means that any other groups defined in the container's image are effectively lost. Under most circumstances, this is not an issue. While this is really only useful on Linux, for consistency, batect makes the same configuration changes regardless of the host operating system. These configuration changes are harmless on OS X.","title":"Build artifacts are owned by root"},{"location":"tips/BuildArtifactsOwnedByRoot.html#build-artifacts-are-owned-by-root","text":"tl;dr If a container produces build artifacts in a mounted volume, enable run_as_current_user , otherwise they'll be owned by the root Unix user On Linux, by default, the Docker daemon runs as root, and so all containers run as root. This means that when a container writes a file to a mounted volume, it is owned by the root Unix user, making it difficult for other users to modify or delete the files. This most often comes up when a build task produces an artifact and writes that artifact to a mounted volume. (On OS X, the Docker daemon runs as the currently logged-in user and so any files created in mounted volumes are owned by that user, so this is not an issue.) To fix this issue, batect can run containers in 'run as current user' mode, ensuring that all files written to a mounted volume are created by the current user, not root. This mode can be enabled on a per-container basis with the run_as_current_user option . When enabled, the following configuration changes are made: The container is run with the current user's UID and GID (equivalent to passing --user $(id -u):$(id -g) to docker run ) An empty directory is mounted into the container at home_directory for the user's home directory. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. A new /etc/passwd file is mounted into the container with two users: root and the current user. The current user's home directory is set to the value of home_directory . (If batect is running as root, then just root is listed and it takes the home directory provided in home_directory .) This means that any other users defined in the container's image are effectively lost. Under most circumstances, this is not an issue. Similarly, a new /etc/group file is mounted into the container with two groups: root and the current user's primary group (usually staff on OS X, and the user's name on Linux). If batect is running as root, then just root is listed. Again, this means that any other groups defined in the container's image are effectively lost. Under most circumstances, this is not an issue. While this is really only useful on Linux, for consistency, batect makes the same configuration changes regardless of the host operating system. These configuration changes are harmless on OS X.","title":"Build artifacts are owned by root"},{"location":"tips/CISetup.html","text":"CI setup \u00b6 tl;dr Set up a Cron job to run docker image prune -f regularly on CI agents If you are using Dockerfiles to define your containers (as opposed to taking a pre-existing image), this can generate a large number of orphaned images (and their associated image layers) over time. While batect goes to great lengths to ensure that containers and networks are cleaned up after every task run, it can't know which images are unused and so it can't safely automatically remove unused images. These orphaned images take up disk space, and, if left unattended, can lead to exhausting all the available disk space. This is especially a problem on CI, where a human might not notice this issue until the disk is full. Therefore, it's recommended that CI servers running batect-based builds have a regular task that removes orphaned images. Docker has a built-in command to do this: docker image prune -f (the -f disables the confirmation prompt). The exact frequency will depend on your usage pattern, but once a day is usually more than sufficient.","title":"CI setup"},{"location":"tips/CISetup.html#ci-setup","text":"tl;dr Set up a Cron job to run docker image prune -f regularly on CI agents If you are using Dockerfiles to define your containers (as opposed to taking a pre-existing image), this can generate a large number of orphaned images (and their associated image layers) over time. While batect goes to great lengths to ensure that containers and networks are cleaned up after every task run, it can't know which images are unused and so it can't safely automatically remove unused images. These orphaned images take up disk space, and, if left unattended, can lead to exhausting all the available disk space. This is especially a problem on CI, where a human might not notice this issue until the disk is full. Therefore, it's recommended that CI servers running batect-based builds have a regular task that removes orphaned images. Docker has a built-in command to do this: docker image prune -f (the -f disables the confirmation prompt). The exact frequency will depend on your usage pattern, but once a day is usually more than sufficient.","title":"CI setup"},{"location":"tips/IDEIntegration.html","text":"IDE integration \u00b6 Coding assistance \u00b6 tl;dr Some IDEs can't provide their advanced features (eg. code completion) when using batect, but there are solutions Many IDEs rely on having the development environment installed locally in order to provide features like code completion, analysis and tool integration. (For example, a Ruby IDE might need access to a Ruby runtime, and a Java IDE might need the target JVM to be installed.) However, if you're using batect, then all of this is in a container and so the IDE can't access it. Some solutions for this include: Some of the JetBrains family of products natively supports using a SDK or runtime from a container (PyCharm and RubyMine are known to work, although notably IntelliJ does not currently support this). There's more information on how to configure this in the PyCharm docs and RubyMine docs . The Visual Studio Code Remote - Containers extension , currently available with the Insiders build of Visual Studio Code gives the option to use local filesystem and code in a Docker container with your chosen language's runtime and other tools. All the extensions and the IDE features, including full IntelliSense, code navigation and debugging can be used. You could run a text-based editor such as Vim or Emacs in a container (managed by batect, of course) that has your required runtime components installed alongside it. (Have you tried something else that worked? Or do you use another IDE or text editor that supports using runtimes inside a container? Please submit a PR to add to the list above.) Editing batect.yml \u00b6 tl;dr If your editor supports schemastore.org for YAML files, you'll get code completion and other nice features when editing batect.yml batect has a schema published on schemastore.org , which means that if your editor supports schemastore.org for YAML files, you'll get code completion, validation and other nice features automatically. Editors known to support this include: Visual Studio Code with the YAML Support by Red Hat extension JetBrains IDEs (such as IntelliJ, PyCharm and RubyMine) starting with the 2018.2 release","title":"IDE integration"},{"location":"tips/IDEIntegration.html#ide-integration","text":"","title":"IDE integration"},{"location":"tips/IDEIntegration.html#coding-assistance","text":"tl;dr Some IDEs can't provide their advanced features (eg. code completion) when using batect, but there are solutions Many IDEs rely on having the development environment installed locally in order to provide features like code completion, analysis and tool integration. (For example, a Ruby IDE might need access to a Ruby runtime, and a Java IDE might need the target JVM to be installed.) However, if you're using batect, then all of this is in a container and so the IDE can't access it. Some solutions for this include: Some of the JetBrains family of products natively supports using a SDK or runtime from a container (PyCharm and RubyMine are known to work, although notably IntelliJ does not currently support this). There's more information on how to configure this in the PyCharm docs and RubyMine docs . The Visual Studio Code Remote - Containers extension , currently available with the Insiders build of Visual Studio Code gives the option to use local filesystem and code in a Docker container with your chosen language's runtime and other tools. All the extensions and the IDE features, including full IntelliSense, code navigation and debugging can be used. You could run a text-based editor such as Vim or Emacs in a container (managed by batect, of course) that has your required runtime components installed alongside it. (Have you tried something else that worked? Or do you use another IDE or text editor that supports using runtimes inside a container? Please submit a PR to add to the list above.)","title":"Coding assistance"},{"location":"tips/IDEIntegration.html#editing-batectyml","text":"tl;dr If your editor supports schemastore.org for YAML files, you'll get code completion and other nice features when editing batect.yml batect has a schema published on schemastore.org , which means that if your editor supports schemastore.org for YAML files, you'll get code completion, validation and other nice features automatically. Editors known to support this include: Visual Studio Code with the YAML Support by Red Hat extension JetBrains IDEs (such as IntelliJ, PyCharm and RubyMine) starting with the 2018.2 release","title":"Editing batect.yml"},{"location":"tips/Performance.html","text":"Performance \u00b6 I/O performance \u00b6 tl;dr If you're seeing slow build times under batect on OS X, volume mount options such as cached might help Info This section only applies to OS X-based hosts, and is only supported by Docker version 17.04 and higher. Docker requires features only found in the Linux kernel, and so on OS X, Docker for Mac runs a lightweight virtual machine to host Docker. However, while this works perfectly fine for most situations, there is some overhead involved in operations that need to work across the host / virtual machine boundary. Usually this overhead is so small that it's not noticeable, but for operations involving mounted volumes, this overhead can be significant. In particular, this can impact compilation operations involving reading and writing many files. There is a way to reduce this overhead significantly: use the volume mount options introduced in Docker 17.04 . In particular, for the typical scenario where you are editing code files on your host's disk and mounting that into a container for compilation, using the cached volume mount mode can result in a significant performance improvement - we saw an improvement in compilation times of ~60% on one Golang project once we started using this. (Before you use these options in another context, you should consult the documentation to understand the implications of the option.) For example, instead of defining your container like this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code working_directory : /code use this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code options : cached # This enables 'cached' mode for the /code mount working_directory : /code Setting this option will not affect Linux hosts, so it's safe to commit and share this in a project where some developers use OS X and others use Linux. Database schema and test data \u00b6 tl;dr Try to do as much work as possible at image build time, rather than doing it every time the container starts A significant amount of time during integration or journey testing with a database can be taken up by preparing the database for use - setting up the schema (usually with some kind of migrations system) and adding the initial test data can take quite some time, especially as the application evolves over time. One way to address this is to bake the schema and test data into the Docker image used for the database, so that this setup cost only has to be paid when building the image or when the setup changes, rather than on every test run. The exact method for doing this will vary depending on the database system you're using, but the general steps that would go in your Dockerfile are: Copy schema and test data scripts into container Temporarily start database daemon Run schema and data scripts against database instance Shut down database daemon Shutdown time \u00b6 tl;dr Make sure signals such as SIGTERM and SIGKILL are being passed to the main process If you notice that post-task cleanup for a container is taking longer than expected, and that container starts the main process from a shell script, make sure that signals such as SIGTERM and SIGKILL are being forwarded to the process. (Otherwise Docker will wait 10 seconds for the application to respond to the signal before just terminating the process.) For example, instead of using: #! /usr/bin/env bash /app/my-really-cool-app --do-stuff use this: #! /usr/bin/env bash exec /app/my-really-cool-app --do-stuff ( source )","title":"Performance"},{"location":"tips/Performance.html#performance","text":"","title":"Performance"},{"location":"tips/Performance.html#io-performance","text":"tl;dr If you're seeing slow build times under batect on OS X, volume mount options such as cached might help Info This section only applies to OS X-based hosts, and is only supported by Docker version 17.04 and higher. Docker requires features only found in the Linux kernel, and so on OS X, Docker for Mac runs a lightweight virtual machine to host Docker. However, while this works perfectly fine for most situations, there is some overhead involved in operations that need to work across the host / virtual machine boundary. Usually this overhead is so small that it's not noticeable, but for operations involving mounted volumes, this overhead can be significant. In particular, this can impact compilation operations involving reading and writing many files. There is a way to reduce this overhead significantly: use the volume mount options introduced in Docker 17.04 . In particular, for the typical scenario where you are editing code files on your host's disk and mounting that into a container for compilation, using the cached volume mount mode can result in a significant performance improvement - we saw an improvement in compilation times of ~60% on one Golang project once we started using this. (Before you use these options in another context, you should consult the documentation to understand the implications of the option.) For example, instead of defining your container like this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code working_directory : /code use this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code options : cached # This enables 'cached' mode for the /code mount working_directory : /code Setting this option will not affect Linux hosts, so it's safe to commit and share this in a project where some developers use OS X and others use Linux.","title":"I/O performance"},{"location":"tips/Performance.html#database-schema-and-test-data","text":"tl;dr Try to do as much work as possible at image build time, rather than doing it every time the container starts A significant amount of time during integration or journey testing with a database can be taken up by preparing the database for use - setting up the schema (usually with some kind of migrations system) and adding the initial test data can take quite some time, especially as the application evolves over time. One way to address this is to bake the schema and test data into the Docker image used for the database, so that this setup cost only has to be paid when building the image or when the setup changes, rather than on every test run. The exact method for doing this will vary depending on the database system you're using, but the general steps that would go in your Dockerfile are: Copy schema and test data scripts into container Temporarily start database daemon Run schema and data scripts against database instance Shut down database daemon","title":"Database schema and test data"},{"location":"tips/Performance.html#shutdown-time","text":"tl;dr Make sure signals such as SIGTERM and SIGKILL are being passed to the main process If you notice that post-task cleanup for a container is taking longer than expected, and that container starts the main process from a shell script, make sure that signals such as SIGTERM and SIGKILL are being forwarded to the process. (Otherwise Docker will wait 10 seconds for the application to respond to the signal before just terminating the process.) For example, instead of using: #! /usr/bin/env bash /app/my-really-cool-app --do-stuff use this: #! /usr/bin/env bash exec /app/my-really-cool-app --do-stuff ( source )","title":"Shutdown time"},{"location":"tips/Proxies.html","text":"Proxies, Docker and batect \u00b6 tl;dr batect will do its best to make things just work with proxies, but you'll need to configure proxies for pulling images yourself Most applications expect to find proxy configuration in a number of environment variables. The most common are: http_proxy : proxy to use for HTTP requests https_proxy : proxy to use for HTTPS requests ftp_proxy : proxy to use for FTP requests no_proxy : comma-separated list of domains or addresses for which connections should bypass the proxy (ie. be direct to the destination) There are three points where a proxy could be required during the lifecycle of a container: at image pull time at build time, after the image has been pulled at run time Each of these are handled slightly differently by Docker, and so batect does its best to make your life easier. At image pull time \u00b6 When pulling an image, the Docker daemon uses any proxy-related environment variables in the Docker daemon's environment to determine whether or not to use a proxy. These settings cannot be set at image pull time, so batect can't configure these settings for you - you must configure them yourself. On OS X, Docker defaults to using your system's proxy settings, and you can change these by going to the Docker icon > Preferences > Proxies. On Linux, you may need to configure the Docker daemon's proxy settings yourself. This page in the Docker documentation gives an example of how to configure a Docker daemon running with systemd. At build time, after the image has been pulled \u00b6 After pulling the base image, all subsequent build steps use the environment variables of the build environment, which is a combination of: any environment variables defined in the base image with ENV instructions any build arguments defined in the Dockerfile with ARG instructions any environment variables defined in the Dockerfile with ENV instructions any of the pre-defined build arguments , if a value is provided for them This last point is the most relevant to proxy settings - as http_proxy , https_proxy , no_proxy etc. are defined as pre-defined build arguments, we can pass the host's proxy environment variables into the build environment as build arguments. batect automatically propagates any proxy environment variables configured on the host as build arguments unless the --no-proxy-vars flag is passed to batect . Note that build arguments are not persisted in the image - they exist only as environment variables at build time. Furthermore, the pre-defined proxy-related build arguments (unlike normal build arguments) do not impact Docker's cache invalidation logic - so if an image build succeeded with http_proxy set to http://brokenproxy , changing http_proxy to http://workingproxy will not cause a rebuild. (The reasoning behind this is that if the build has succeeded with one proxy, then switching to another proxy should have no impact.) At run time \u00b6 The set of run time environment variables is defined by: any environment variables defined in the image (including any base images) with ENV instructions any container-specific environment variables specified in the container or task in batect.yml batect automatically propagates any proxy environment variables configured on the host as environment variables unless the --no-proxy-vars flag is passed to batect . Starting with v0.14, if propagating proxy environment variables is enabled, and any proxy environment variable recognised by batect is set, batect will also add the names of all containers started as part of the task to no_proxy and NO_PROXY (or create those environment variables if they're not set). This ensures that inter-container communication is not proxied. Proxy environment variables recognised by batect \u00b6 batect will propagate the following proxy-related environment variables: http_proxy HTTP_PROXY https_proxy HTTPS_PROXY ftp_proxy FTP_PROXY no_proxy NO_PROXY Starting with v0.18, batect will add missing environment variables if only one in a pair is defined. (For example, if http_proxy is defined, but HTTP_PROXY isn't, then both http_proxy and HTTP_PROXY are propagated, with HTTP_PROXY set to the same value as http_proxy .) Proxies running on the host machine \u00b6 If you run a local proxy on your host machine such as Cntlm , referring to this proxy with localhost will not work from inside a Docker container, as localhost refers to the container, not the host machine. Starting with v0.16, if you are running batect on OS X with Docker 17.06 or later, batect will automatically rewrite proxy-related environment variables that refer to localhost , 127.0.0.1 or ::1 so that they refer to the host machine. If you are running batect on Linux, or using an older version of Docker, batect will not rewrite proxy-related environment variables. Support for Linux will be added in the future, check this issue on GitHub for updates.","title":"Proxies"},{"location":"tips/Proxies.html#proxies-docker-and-batect","text":"tl;dr batect will do its best to make things just work with proxies, but you'll need to configure proxies for pulling images yourself Most applications expect to find proxy configuration in a number of environment variables. The most common are: http_proxy : proxy to use for HTTP requests https_proxy : proxy to use for HTTPS requests ftp_proxy : proxy to use for FTP requests no_proxy : comma-separated list of domains or addresses for which connections should bypass the proxy (ie. be direct to the destination) There are three points where a proxy could be required during the lifecycle of a container: at image pull time at build time, after the image has been pulled at run time Each of these are handled slightly differently by Docker, and so batect does its best to make your life easier.","title":"Proxies, Docker and batect"},{"location":"tips/Proxies.html#at-image-pull-time","text":"When pulling an image, the Docker daemon uses any proxy-related environment variables in the Docker daemon's environment to determine whether or not to use a proxy. These settings cannot be set at image pull time, so batect can't configure these settings for you - you must configure them yourself. On OS X, Docker defaults to using your system's proxy settings, and you can change these by going to the Docker icon > Preferences > Proxies. On Linux, you may need to configure the Docker daemon's proxy settings yourself. This page in the Docker documentation gives an example of how to configure a Docker daemon running with systemd.","title":"At image pull time"},{"location":"tips/Proxies.html#at-build-time-after-the-image-has-been-pulled","text":"After pulling the base image, all subsequent build steps use the environment variables of the build environment, which is a combination of: any environment variables defined in the base image with ENV instructions any build arguments defined in the Dockerfile with ARG instructions any environment variables defined in the Dockerfile with ENV instructions any of the pre-defined build arguments , if a value is provided for them This last point is the most relevant to proxy settings - as http_proxy , https_proxy , no_proxy etc. are defined as pre-defined build arguments, we can pass the host's proxy environment variables into the build environment as build arguments. batect automatically propagates any proxy environment variables configured on the host as build arguments unless the --no-proxy-vars flag is passed to batect . Note that build arguments are not persisted in the image - they exist only as environment variables at build time. Furthermore, the pre-defined proxy-related build arguments (unlike normal build arguments) do not impact Docker's cache invalidation logic - so if an image build succeeded with http_proxy set to http://brokenproxy , changing http_proxy to http://workingproxy will not cause a rebuild. (The reasoning behind this is that if the build has succeeded with one proxy, then switching to another proxy should have no impact.)","title":"At build time, after the image has been pulled"},{"location":"tips/Proxies.html#at-run-time","text":"The set of run time environment variables is defined by: any environment variables defined in the image (including any base images) with ENV instructions any container-specific environment variables specified in the container or task in batect.yml batect automatically propagates any proxy environment variables configured on the host as environment variables unless the --no-proxy-vars flag is passed to batect . Starting with v0.14, if propagating proxy environment variables is enabled, and any proxy environment variable recognised by batect is set, batect will also add the names of all containers started as part of the task to no_proxy and NO_PROXY (or create those environment variables if they're not set). This ensures that inter-container communication is not proxied.","title":"At run time"},{"location":"tips/Proxies.html#proxy-environment-variables-recognised-by-batect","text":"batect will propagate the following proxy-related environment variables: http_proxy HTTP_PROXY https_proxy HTTPS_PROXY ftp_proxy FTP_PROXY no_proxy NO_PROXY Starting with v0.18, batect will add missing environment variables if only one in a pair is defined. (For example, if http_proxy is defined, but HTTP_PROXY isn't, then both http_proxy and HTTP_PROXY are propagated, with HTTP_PROXY set to the same value as http_proxy .)","title":"Proxy environment variables recognised by batect"},{"location":"tips/Proxies.html#proxies-running-on-the-host-machine","text":"If you run a local proxy on your host machine such as Cntlm , referring to this proxy with localhost will not work from inside a Docker container, as localhost refers to the container, not the host machine. Starting with v0.16, if you are running batect on OS X with Docker 17.06 or later, batect will automatically rewrite proxy-related environment variables that refer to localhost , 127.0.0.1 or ::1 so that they refer to the host machine. If you are running batect on Linux, or using an older version of Docker, batect will not rewrite proxy-related environment variables. Support for Linux will be added in the future, check this issue on GitHub for updates.","title":"Proxies running on the host machine"},{"location":"tips/WaitingForDependenciesToBeReady.html","text":"Waiting for dependencies to be ready \u00b6 tl;dr Make sure your image has a health check defined, and batect will take care of the rest When running integration or end-to-end tests, you might need to start a number of external dependencies for your application, such as databases or fakes for external services. However, having these dependencies just running usually isn't sufficient - they also need to be ready to respond to requests. For example, your database of choice might take a few seconds to initialise and start accepting queries, and during this time, any requests to it will fail. So we'd like to avoid starting our tests before we know these things are ready, otherwise they'll fail unnecessarily. batect supports this exact requirement by taking advantage of Docker's health check feature : If a container's image has a health check defined, batect won't start any containers that depend on it until the health check reports that it is healthy. If a container's image does not have a health check defined, it is treated as though it has a health check that immediately reported that it is healthy. If the health check fails to report that the container is healthy before the timeout period expires, batect won't start any other containers and will abort the task. There's a collection of sample health check scripts provided by Docker you can use as inspiration, and the sample projects use this technique extensively.","title":"Waiting for dependencies to be ready"},{"location":"tips/WaitingForDependenciesToBeReady.html#waiting-for-dependencies-to-be-ready","text":"tl;dr Make sure your image has a health check defined, and batect will take care of the rest When running integration or end-to-end tests, you might need to start a number of external dependencies for your application, such as databases or fakes for external services. However, having these dependencies just running usually isn't sufficient - they also need to be ready to respond to requests. For example, your database of choice might take a few seconds to initialise and start accepting queries, and during this time, any requests to it will fail. So we'd like to avoid starting our tests before we know these things are ready, otherwise they'll fail unnecessarily. batect supports this exact requirement by taking advantage of Docker's health check feature : If a container's image has a health check defined, batect won't start any containers that depend on it until the health check reports that it is healthy. If a container's image does not have a health check defined, it is treated as though it has a health check that immediately reported that it is healthy. If the health check fails to report that the container is healthy before the timeout period expires, batect won't start any other containers and will abort the task. There's a collection of sample health check scripts provided by Docker you can use as inspiration, and the sample projects use this technique extensively.","title":"Waiting for dependencies to be ready"},{"location":"tools/CircleCI.html","text":"CircleCI \u00b6 tl;dr Use a machine executor with an image that has a recent version of Docker. CircleCI's recent machine executor images include everything batect requires, so all that needs to be done to use batect with CircleCI is to configure it to use one of those images. A list of available images is published in the CircleCI documentation here . batect requires an image with a compatible version of Docker - currently version 17.06 or newer. Adding the following to your .circleci/config.yml file instructs CircleCI to use a machine executor with the 201808-01 image, which contains Docker 18.06: version : 2 jobs : build : machine : enabled : true image : circleci/classic:201808-01 steps : - checkout - run : ./batect ... You can see a full example of using batect with CircleCI in the Golang sample project .","title":"CircleCI"},{"location":"tools/CircleCI.html#circleci","text":"tl;dr Use a machine executor with an image that has a recent version of Docker. CircleCI's recent machine executor images include everything batect requires, so all that needs to be done to use batect with CircleCI is to configure it to use one of those images. A list of available images is published in the CircleCI documentation here . batect requires an image with a compatible version of Docker - currently version 17.06 or newer. Adding the following to your .circleci/config.yml file instructs CircleCI to use a machine executor with the 201808-01 image, which contains Docker 18.06: version : 2 jobs : build : machine : enabled : true image : circleci/classic:201808-01 steps : - checkout - run : ./batect ... You can see a full example of using batect with CircleCI in the Golang sample project .","title":"CircleCI"},{"location":"tools/Docker.html","text":"Docker \u00b6 Building and pushing an image \u00b6 You can see an example of building and pushing an image from batect in the Java sample project .","title":"Docker"},{"location":"tools/Docker.html#docker","text":"","title":"Docker"},{"location":"tools/Docker.html#building-and-pushing-an-image","text":"You can see an example of building and pushing an image from batect in the Java sample project .","title":"Building and pushing an image"},{"location":"tools/Golang.html","text":"Golang \u00b6 You can see a full example of using batect with Golang in the Golang sample project . Caching dependencies \u00b6 tl;dr Mount a directory into your container for your GOPATH , otherwise you'll have to download and compile your dependencies every time the build runs Golang caches the source and binaries for dependencies under your GOPATH . By default, this is at $HOME/go . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Golang will have to download and compile all of your dependencies again, significantly slowing down the build. The solution to this is to mount a directory that persists between builds into your container for your GOPATH . For example, the official Golang Docker images set GOPATH to /go , so mounting the directory .go-cache in your project to /go inside the container will allow your dependencies to be persisted across builds.","title":"Golang"},{"location":"tools/Golang.html#golang","text":"You can see a full example of using batect with Golang in the Golang sample project .","title":"Golang"},{"location":"tools/Golang.html#caching-dependencies","text":"tl;dr Mount a directory into your container for your GOPATH , otherwise you'll have to download and compile your dependencies every time the build runs Golang caches the source and binaries for dependencies under your GOPATH . By default, this is at $HOME/go . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Golang will have to download and compile all of your dependencies again, significantly slowing down the build. The solution to this is to mount a directory that persists between builds into your container for your GOPATH . For example, the official Golang Docker images set GOPATH to /go , so mounting the directory .go-cache in your project to /go inside the container will allow your dependencies to be persisted across builds.","title":"Caching dependencies"},{"location":"tools/Java.html","text":"Java \u00b6 Gradle \u00b6 You can see an example of configuring and using Java and Gradle with batect in the Java sample project . Caching dependencies \u00b6 tl;dr Mount a local directory as the ~/.gradle directory within the container, otherwise you'll have to download your dependencies every time the build runs By default, Gradle downloads all of your application's dependencies to the ~/.gradle directory. However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Gradle will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to mount a local directory (eg. .gradle-cache ) into the container at ~/.gradle , so that these downloaded dependencies are persisted between builds. Note that you can't use ~ in the container path for a volume mount: If you're using run as current user mode , use the home directory you specified for home_directory . If you're not using run as current user mode , use /root as the home directory, as the vast majority of containers default to the root user and use this as the root user's home directory. Warning With this configuration, you will not be able to run more than one task at a time. This is due to a known issue with Gradle . Disabling the Gradle daemon \u00b6 tl;dr Set the environment variable GRADLE_OPTS to -Dorg.gradle.daemon=false When Gradle starts, it has to load itself and then compile and load your build script so that it can execute it. This can take a noticeable amount of time for larger projects, so, by default, it starts a daemon that remains running and ready to start your build without having to load or compile anything. However, when Gradle is running inside an ephemeral container like the ones created by batect, this daemon is pointless - it will be terminated alongside the rest of the container at the end of the build. In fact, the cost of starting the daemon means that this is actually counter-productive, because we'll pay the performance penalty of starting the daemon every time when we won't then benefit from it in later builds. Therefore, it's best to disable the daemon when running Gradle inside a container. This can be done by setting the GRADLE_OPTS environment variable to -Dorg.gradle.daemon=false .","title":"Java"},{"location":"tools/Java.html#java","text":"","title":"Java"},{"location":"tools/Java.html#gradle","text":"You can see an example of configuring and using Java and Gradle with batect in the Java sample project .","title":"Gradle"},{"location":"tools/Java.html#caching-dependencies","text":"tl;dr Mount a local directory as the ~/.gradle directory within the container, otherwise you'll have to download your dependencies every time the build runs By default, Gradle downloads all of your application's dependencies to the ~/.gradle directory. However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Gradle will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to mount a local directory (eg. .gradle-cache ) into the container at ~/.gradle , so that these downloaded dependencies are persisted between builds. Note that you can't use ~ in the container path for a volume mount: If you're using run as current user mode , use the home directory you specified for home_directory . If you're not using run as current user mode , use /root as the home directory, as the vast majority of containers default to the root user and use this as the root user's home directory. Warning With this configuration, you will not be able to run more than one task at a time. This is due to a known issue with Gradle .","title":"Caching dependencies"},{"location":"tools/Java.html#disabling-the-gradle-daemon","text":"tl;dr Set the environment variable GRADLE_OPTS to -Dorg.gradle.daemon=false When Gradle starts, it has to load itself and then compile and load your build script so that it can execute it. This can take a noticeable amount of time for larger projects, so, by default, it starts a daemon that remains running and ready to start your build without having to load or compile anything. However, when Gradle is running inside an ephemeral container like the ones created by batect, this daemon is pointless - it will be terminated alongside the rest of the container at the end of the build. In fact, the cost of starting the daemon means that this is actually counter-productive, because we'll pay the performance penalty of starting the daemon every time when we won't then benefit from it in later builds. Therefore, it's best to disable the daemon when running Gradle inside a container. This can be done by setting the GRADLE_OPTS environment variable to -Dorg.gradle.daemon=false .","title":"Disabling the Gradle daemon"},{"location":"tools/Node.html","text":"Node.js \u00b6 Issues with signals not being handled correctly \u00b6 tl;dr If signals such as SIGINT (which is what happens when you press Ctrl+C) aren't being handled correctly by your Node.js-based application, enable enable_init_process for that container Node.js does not behave correctly when it is running as PID 1, which is what happens when running Node.js inside a container. The most noticeable issue this causes is that applications do not respond correctly to signals such as SIGINT (which is generated when you press Ctrl+C). The solution is to run another process (an 'init process') as PID 1, which then runs your application and handles and forwards signals to it. Docker has a slimmed-down init process built in that is designed for just this scenario. You can enable it for a container in batect by setting enable_init_process to true . This article has a more detailed explanation of what is happening and why an init process solves this problem.","title":"Node.js"},{"location":"tools/Node.html#nodejs","text":"","title":"Node.js"},{"location":"tools/Node.html#issues-with-signals-not-being-handled-correctly","text":"tl;dr If signals such as SIGINT (which is what happens when you press Ctrl+C) aren't being handled correctly by your Node.js-based application, enable enable_init_process for that container Node.js does not behave correctly when it is running as PID 1, which is what happens when running Node.js inside a container. The most noticeable issue this causes is that applications do not respond correctly to signals such as SIGINT (which is generated when you press Ctrl+C). The solution is to run another process (an 'init process') as PID 1, which then runs your application and handles and forwards signals to it. Docker has a slimmed-down init process built in that is designed for just this scenario. You can enable it for a container in batect by setting enable_init_process to true . This article has a more detailed explanation of what is happening and why an init process solves this problem.","title":"Issues with signals not being handled correctly"},{"location":"tools/Ruby.html","text":"Ruby \u00b6 Bundler \u00b6 You can see an example of configuring and using Ruby and Bundler with batect in the Ruby sample project . Caching dependencies \u00b6 tl;dr Set the BUNDLE_PATH environment variable to a directory within your mounted code directory, otherwise you'll have to download your dependencies every time the build runs By default, Bundler downloads all of your application's dependencies to the ~/.bundle directory. However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Bundler will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to set the BUNDLE_PATH environment variable to a directory that persists between builds. If you're already mounting your application's code into the container, then the simplest thing to do is to set BUNDLE_PATH to a directory within that mounted directory. For example, if you're mounting your application's code into the container at /code , set BUNDLE_PATH to /code/.bundle-cache .","title":"Ruby"},{"location":"tools/Ruby.html#ruby","text":"","title":"Ruby"},{"location":"tools/Ruby.html#bundler","text":"You can see an example of configuring and using Ruby and Bundler with batect in the Ruby sample project .","title":"Bundler"},{"location":"tools/Ruby.html#caching-dependencies","text":"tl;dr Set the BUNDLE_PATH environment variable to a directory within your mounted code directory, otherwise you'll have to download your dependencies every time the build runs By default, Bundler downloads all of your application's dependencies to the ~/.bundle directory. However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Bundler will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to set the BUNDLE_PATH environment variable to a directory that persists between builds. If you're already mounting your application's code into the container, then the simplest thing to do is to set BUNDLE_PATH to a directory within that mounted directory. For example, if you're mounting your application's code into the container at /code , set BUNDLE_PATH to /code/.bundle-cache .","title":"Caching dependencies"},{"location":"tools/TravisCI.html","text":"Travis CI \u00b6 tl;dr Use the Xenial environment, enable Docker and you're all set. Travis CI's Xenial environment includes everything batect requires, so all that needs to be done to use batect with Travis CI is to enable the Docker service. Adding the following to your .travis.yml file selects the Xenial environment and enables Docker: dist : xenial services : - docker You can see a full example of using batect with Travis CI in the Java sample project .","title":"Travis CI"},{"location":"tools/TravisCI.html#travis-ci","text":"tl;dr Use the Xenial environment, enable Docker and you're all set. Travis CI's Xenial environment includes everything batect requires, so all that needs to be done to use batect with Travis CI is to enable the Docker service. Adding the following to your .travis.yml file selects the Xenial environment and enables Docker: dist : xenial services : - docker You can see a full example of using batect with Travis CI in the Java sample project .","title":"Travis CI"}]}